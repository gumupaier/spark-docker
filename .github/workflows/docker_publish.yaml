name: Spark Docker Image Publish

on: [push]

jobs:
  build-base-image:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        repository: [spark]
        java_version: [8]
        hadoop_version: [3.2.1, 3.1.3, 2.9.2, 2.8.5, 2.7.7]
    steps:
      - uses: actions/checkout@v1
      - run: echo ${{secrets.DOCKER_PASSWORD}} | docker login -u ${{secrets.DOCKER_USERNAME}} --password-stdin
      - run: docker build -q
          -t ${{secrets.DOCKER_USERNAME}}/${{matrix.repository}}:base-hadoop-${{matrix.hadoop_version}}-java${{matrix.java_version}}
          --build-arg HADOOP_VERSION=${{matrix.hadoop_version}}
          --build-arg JAVA_VERSION=${{matrix.java_version}}
          src/base
      - run: docker push ${{secrets.DOCKER_USERNAME}}/${{matrix.repository}}:base-hadoop${{matrix.hadoop_version}}-java${{matrix.java_version}}
      - run: docker rmi ${{secrets.DOCKER_USERNAME}}/${{matrix.repository}}:base-hadoop${{matrix.hadoop_version}}-java${{matrix.java_version}}

  build-spark-image:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        repository: [spark]
        java_version: [8]
        spark_version: [2.4.4, 2.3.4]
        spark_hadoop_version: [2.7]
        hadoop_version: [3.2.1, 3.1.3, 2.9.2, 2.8.5, 2.7.7]
    needs: build-base-image
    steps:
      - uses: actions/checkout@v1
      - run: echo ${{secrets.DOCKER_PASSWORD}} | docker login -u ${{secrets.DOCKER_USERNAME}} --password-stdin
      - run: docker build -q
          -t ${{secrets.DOCKER_USERNAME}}/${{matrix.repository}}:${{matrix.spark_version}}-hadoop-${{matrix.hadoop_version}}-java${{matrix.java_version}}
          --build-arg SPARK_VERSION=${{matrix.spark_version}}
          --build-arg SPARK_HADOOP_VERSION=${{matrix.spark_hadoop_version}}
          --build-arg HADOOP_VERSION=${{matrix.hadoop_version}}
          --build-arg JAVA_VERSION=${{matrix.java_version}}
          src/spark
      - run: docker push ${{secrets.DOCKER_USERNAME}}/${{matrix.repository}}:${{matrix.spark_version}}-hadoop-${{matrix.hadoop_version}}-java${{matrix.java_version}}
      - run: docker rmi ${{secrets.DOCKER_USERNAME}}/${{matrix.repository}}:${{matrix.spark_version}}-hadoop-${{matrix.hadoop_version}}-java${{matrix.java_version}}

  build-pyspark-image:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        repository: [pyspark]
        java_version: [8]
        spark_version: [2.4.4, 2.3.4]
        hadoop_version: [3.2.1, 3.1.3, 2.9.2, 2.8.5, 2.7.7]
    needs: build-spark-image
    steps:
      - uses: actions/checkout@v1
      - run: echo ${{secrets.DOCKER_PASSWORD}} | docker login -u ${{secrets.DOCKER_USERNAME}} --password-stdin
      - run: docker build -q
          -t ${{secrets.DOCKER_USERNAME}}/${{matrix.repository}}:${{matrix.spark_version}}-hadoop-${{matrix.hadoop_version}}-java${{matrix.java_version}}
          --build-arg SPARK_VERSION=${{matrix.spark_version}}
          --build-arg HADOOP_VERSION=${{matrix.hadoop_version}}
          --build-arg JAVA_VERSION=${{matrix.java_version}}
          src/pyspark
      - run: docker push ${{secrets.DOCKER_USERNAME}}/${{matrix.repository}}:${{matrix.spark_version}}-hadoop-${{matrix.hadoop_version}}-java${{matrix.java_version}}
      - run: docker rmi ${{secrets.DOCKER_USERNAME}}/${{matrix.repository}}:${{matrix.spark_version}}-hadoop-${{matrix.hadoop_version}}-java${{matrix.java_version}}
