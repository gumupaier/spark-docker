# Written by Mutlu Polatcna
# 22.11.2019
version: "3"
services:
  spark-master:
    image: mpolatcan/pyspark:2.3.4-hadoop-3.2.1-java8
    container_name: spark-master
    hostname: spark-master
    environment:
      HADOOP_DAEMONS: |
          resourcemanager
      SPARK_SERVICES: |
          livy
      DFS_NAMENODE_HOSTNAME: "hdfs-master"
      YARN_SCHEDULER_MINIMUM_ALLOCATION_MB: "128"
      YARN_SCHEDULER_MAXIMUM_ALLOCATION_MB: "1536"
    ports:
      - 8088:8088
      - 8998:8998

  spark-worker:
    image: mpolatcan/pyspark:2.3.4-hadoop-3.2.1-java8
    environment:
      HADOOP_DAEMONS: |
          nodemanager
      DFS_NAMENODE_HOSTNAME: "hdfs-master"
      YARN_RESOURCEMANAGER_HOSTNAME: "spark-master"
      YARN_NODEMANAGER_RESOURCE_MEMORY_MB: "1536"
      YARN_NODEMANAGER_RESOURCE_CPU_VCORES: "2"
    ports:
      - 8042

  hdfs-master:
    image: mpolatcan/pyspark:2.3.4-hadoop-3.2.1-java8
    container_name: hdfs-master
    hostname: hdfs-master
    environment:
      HADOOP_DAEMONS: |
          namenode
    ports:
      - 9870:9870

  hdfs-slave:
    image: mpolatcan/pyspark:2.3.4-hadoop-3.2.1-java8
    environment:
      HADOOP_DAEMONS: |
          datanode
      DFS_NAMENODE_HOSTNAME: "hdfs-master"
    ports:
      - 9864