#!/usr/bin/env bash
function load_config() {
  if [[ "$2" != "NULL" && "$4" == "spark" ]]; then
      printf "$1\t$2\n" >> "${SPARK_CONF_DIR}/$3"
  elif [[ "$2" != "NULL" && "$4" == "livy" ]]; then
      printf "$1 = $2\n" >> "${LIVY_CONF_DIR}/$3"
  fi
}

load_config "spark.default.parallelism" ${SPARK_DEFAULT_PARALLELISM:=NULL} "spark-defaults.conf" "spark"
load_config "spark.driver.cores" ${SPARK_DRIVER_CORES:=1} "spark-defaults.conf" "spark"
load_config "spark.driver.maxResultSize" ${SPARK_DRIVER_MAXRESULTSIZE:=1g} "spark-defaults.conf" "spark"
load_config "spark.driver.memory" ${SPARK_DRIVER_MEMORY:=1g} "spark-defaults.conf" "spark"
load_config "spark.driver.memoryOverhead" ${SPARK_DRIVER_MEMORYOVERHEAD:=NULL} "spark-defaults.conf" "spark"
load_config "spark.driver.supervise" ${SPARK_DRIVER_SUPERVISE:=false} "spark-defaults.conf" "spark"
load_config "spark.driver.extraClassPath" ${SPARK_DRIVER_EXTRACLASSPATH:=NULL} "spark-defaults.conf" "spark"
load_config "spark.driver.extraJavaOptions" ${SPARK_DRIVER_EXTRAJAVAOPTIONS:=NULL} "spark-defaults.conf" "spark"
load_config "spark.driver.extraLibraryPath" ${SPARK_DRIVER_EXTRALIBRARYPATH:=NULL} "spark-defaults.conf" "spark"
load_config "spark.driver.userClassPathFirst" ${SPARK_DRIVER_USERCLASSPATHFIRST:=NULL} "spark-defaults.conf" "spark"
load_config "spark.driver.blockManager.port" ${SPARK_DRIVER_BLOCKMANAGER_PORT:=NULL} "spark-defaults.conf" "spark"
load_config "spark.driver.bindAddress" ${SPARK_DRIVER_BINDADDRESS:=NULL} "spark-defaults.conf" "spark"
load_config "spark.driver.host" ${SPARK_DRIVER_HOST:=NULL} "spark-defaults.conf" "spark"
load_config "spark.driver.port" ${SPARK_DRIVER_PORT:=NULL} "spark-defaults.conf" "spark"
load_config "spark.executor.memory" ${SPARK_EXECUTOR_MEMORY:=1g} "spark-defaults.conf" "spark"
load_config "spark.executor.memoryOverhead" ${SPARK_EXECUTOR_MEMORYOVERHEAD:=NULL} "spark-defaults.conf" "spark"
load_config "spark.executor.extraClassPath" ${SPARK_EXECUTOR_EXTRACLASSPATH:=NULL} "spark-defaults.conf" "spark"
load_config "spark.executor.extraJavaOptions" ${SPARK_EXECUTOR_EXTRAJAVAOPTIONS:=NULL} "spark-defaults.conf" "spark"
load_config "spark.executor.extraLibraryPath" ${SPARK_EXECUTOR_EXTRALIBRARYPATH:=NULL} "spark-defaults.conf" "spark"
load_config "spark.executor.userClassPathFirst" ${SPARK_EXECUTOR_USERCLASSPATHFIRST:=false} "spark-defaults.conf" "spark"
load_config "spark.executor.logs.rolling.maxRetainedFiles" ${SPARK_EXECUTOR_LOGS_ROLLING_MAXRETAINEDFILES:=NULL} "spark-defaults.conf" "spark"
load_config "spark.executor.logs.rolling.enableCompression" ${SPARK_EXECUTOR_LOGS_ROLLING_ENABLECOMPRESSION:=false} "spark-defaults.conf" "spark"
load_config "spark.executor.logs.rolling.maxSize" ${SPARK_EXECUTOR_LOGS_ROLLING_MAXSIZE:=NULL} "spark-defaults.conf" "spark"
load_config "spark.executor.logs.rolling.strategy" ${SPARK_EXECUTOR_LOGS_ROLLING_STRATEGY:=NULL} "spark-defaults.conf" "spark"
load_config "spark.executor.logs.rolling.time.interval" ${SPARK_EXECUTOR_LOGS_ROLLING_TIME_INTERVAL:=daily} "spark-defaults.conf" "spark"
load_config "spark.executor.pyspark.memory" ${SPARK_EXECUTOR_PYSPARK_MEMORY:=NULL} "spark-defaults.conf" "spark"
load_config "spark.executor.cores" ${SPARK_EXECUTOR_CORES:=1} "spark-defaults.conf" "spark"
load_config "spark.executor.heartbeatInterval" ${SPARK_EXECUTOR_HEARTBEATINTERVAL:=10s} "spark-defaults.conf" "spark"
load_config "spark.executor.instances" ${SPARK_EXECUTOR_INSTANCES:=NULL} "spark-defaults.conf" "spark"
load_config "spark.extraListeners" ${SPARK_EXTRALISTENERS:=NULL} "spark-defaults.conf" "spark"
load_config "spark.local.dir" ${SPARK_LOCAL_DIR:=/tmp} "spark-defaults.conf" "spark"
load_config "spark.logConf" ${SPARK_LOGCONF:=false} "spark-defaults.conf" "spark"
load_config "spark.master" ${SPARK_MASTER:=yarn} "spark-defaults.conf" "spark"
load_config "spark.submit.deployMode" ${SPARK_SUBMIT_DEPLOYMODE:=NULL} "spark-defaults.conf" "spark"
load_config "spark.submit.pyFiles" ${SPARK_SUBMIT_PYFILES:=NULL} "spark-defaults.conf" "spark"
load_config "spark.log.callerContext" ${SPARK_LOG_CALLERCONTEXT:=NULL} "spark-defaults.conf" "spark"
load_config "spark.redaction.regex" ${SPARK_REDACTION_REGEX:=NULL} "spark-defaults.conf" "spark"
load_config "spark.python.profile" ${SPARK_PYTHON_PROFILE:=false} "spark-defaults.conf" "spark"
load_config "spark.python.profile.dump" ${SPARK_PYTHON_PROFILE_DUMP:=NULL} "spark-defaults.conf" "spark"
load_config "spark.python.worker.memory" ${SPARK_PYTHON_WORKER_MEMORY:=512m} "spark-defaults.conf" "spark"
load_config "spark.python.worker.reuse" ${SPARK_PYTHON_WORKER_REUSE:=true} "spark-defaults.conf" "spark"
load_config "spark.files" ${SPARK_FILES:=NULL} "spark-defaults.conf" "spark"
load_config "spark.files.fetchTimeout" ${SPARK_FILES_FETCHTIMEOUT:=60s} "spark-defaults.conf" "spark"
load_config "spark.files.useFetchCache" ${SPARK_FILES_USEFETCHCACHE:=true} "spark-defaults.conf" "spark"
load_config "spark.files.overwrite" ${SPARK_FILES_OVERWRITE:=false} "spark-defaults.conf" "spark"
load_config "spark.files.maxPartitionBytes" ${SPARK_FILES_MAXPARTITIONBYTES:=134217728} "spark-defaults.conf" "spark"
load_config "spark.files.openCostInBytes" ${SPARK_FILES_OPENCOSTINBYTES:=4194304} "spark-defaults.conf" "spark"
load_config "spark.jars" ${SPARK_JARS:=NULL} "spark-defaults.conf" "spark"
load_config "spark.jars.packages" ${SPARK_JARS_PACKAGES:=NULL} "spark-defaults.conf" "spark"
load_config "spark.jars.excludes" ${SPARK_JARS_EXCLUDES:=NULL} "spark-defaults.conf" "spark"
load_config "spark.jars.ivy" ${SPARK_JARS_IVY:=NULL} "spark-defaults.conf" "spark"
load_config "spark.jars.ivySettings" ${SPARK_JARS_IVYSETTINGS:=NULL} "spark-defaults.conf" "spark"
load_config "spark.jars.repositories" ${SPARK_JARS_REPOSITORIES:=NULL} "spark-defaults.conf" "spark"
load_config "spark.pyspark.driver.python" ${SPARK_PYSPARK_DRIVER_PYTHON:=NULL} "spark-defaults.conf" "spark"
load_config "spark.pyspark.python" ${SPARK_PYSPARK_PYTHON:=NULL} "spark-defaults.conf" "spark"
load_config "spark.reducer.maxSizeInFlight" ${SPARK_REDUCER_MAXSIZEINFLIGHT:=48m} "spark-defaults.conf" "spark"
load_config "spark.reducer.maxReqsInFlight" ${SPARK_REDUCER_MAXREQSINFLIGHT:=NULL} "spark-defaults.conf" "spark"
load_config "spark.reducer.maxBlocksInFlightPerAddress" ${SPARK_REDUCER_MAXBLOCKSINFLIGHTPERADDRESS:=NULL} "spark-defaults.conf" "spark"
load_config "spark.maxRemoteBlockSizeFetchToMem" ${SPARK_MAXREMOTEBLOCKSIZEFETCHTOMEM:=NULL} "spark-defaults.conf" "spark"
load_config "spark.shuffle.compress" ${SPARK_SHUFFLE_COMPRESS:=true} "spark-defaults.conf" "spark"
load_config "spark.shuffle.file.buffer" ${SPARK_SHUFFLE_FILE_BUFFER:=32k} "spark-defaults.conf" "spark"
load_config "spark.shuffle.io.maxRetries" ${SPARK_SHUFFLE_IO_MAXRETRIES:=3} "spark-defaults.conf" "spark"
load_config "spark.shuffle.io.numConnectionsPerPeer" ${SPARK_SHUFFLE_IO_NUMCONNECTIONSPERPEER:=1} "spark-defaults.conf" "spark"
load_config "spark.shuffle.io.preferDirectBufs" ${SPARK_SHUFFLE_IO_PREFERDIRECTBUFS:=true} "spark-defaults.conf" "spark"
load_config "spark.shuffle.io.retryWait" ${SPARK_SHUFFLE_IO_RETRYWAIT:=5s} "spark-defaults.conf" "spark"
load_config "spark.shuffle.io.encryption.enabled" ${SPARK_SHUFFLE_IO_ENCRYPTION_ENABLED:=false} "spark-defaults.conf" "spark"
load_config "spark.shuffle.io.encryption.keySizeBits" ${SPARK_SHUFFLE_IO_ENCRYPTION_KEYSIZEBITS:=128} "spark-defaults.conf" "spark"
load_config "spark.shuffle.io.encryption.keygen.algorithm" ${SPARK_SHUFFLE_IO_ENCRYPTION_KEYGEN_ALGORITHM:=HmacSHA1} "spark-defaults.conf" "spark"
load_config "spark.shuffle.service.enabled" ${SPARK_SHUFFLE_SERVICE_ENABLED:=false} "spark-defaults.conf" "spark"
load_config "spark.shuffle.service.port" ${SPARK_SHUFFLE_SERVICE_PORT:=7337} "spark-defaults.conf" "spark"
load_config "spark.shuffle.service.index.cache.size" ${SPARK_SHUFFLE_SERVICE_INDEX_CACHE_SIZE:=100m} "spark-defaults.conf" "spark"
load_config "spark.shuffle.maxChunksBeingTransferred" ${SPARK_SHUFFLE_MAXCHUNKSBEINGTRANSFERRED:=NULL} "spark-defaults.conf" "spark"
load_config "spark.shuffle.sort.bypassMergeThreshold" ${SPARK_SHUFFLE_SORT_BYPASSMERGETHRESHOLD:=200} "spark-defaults.conf" "spark"
load_config "spark.shuffle.spill.compress" ${SPARK_SHUFFLE_SPILL_COMPRESS:=true} "spark-defaults.conf" "spark"
load_config "spark.shuffle.registration.timeout" ${SPARK_SHUFFLE_REGISTRATION_TIMEOUT:=5000} "spark-defaults.conf" "spark"
load_config "spark.shuffle.registration.maxAttempts" ${SPARK_SHUFFLE_REGISTRATION_MAXATTEMPTS:=3} "spark-defaults.conf" "spark"
load_config "spark.shuffle.memoryFraction" ${SPARK_SHUFFLE_MEMORYFRACTION:=0.2} "spark-defaults.conf" "spark"
load_config "spark.eventlog.logBlockUpdates.enabled" ${SPARK_EVENTLOG_LOGBLOCKUPDATES_ENABLED:=false} "spark-defaults.conf" "spark"
load_config "spark.eventlog.longForm.enabled" ${SPARK_EVENTLOG_LONGFORM_ENABLED:=false} "spark-defaults.conf" "spark"
load_config "spark.eventlog.compress" ${SPARK_EVENTLOG_COMPRESS:=false} "spark-defaults.conf" "spark"
load_config "spark.eventlog.dir" ${SPARK_EVENTLOG_DIR:=file:///tmp/spark-events} "spark-defaults.conf" "spark"
load_config "spark.eventlog.enabled" ${SPARK_EVENTLOG_ENABLED:=false} "spark-defaults.conf" "spark"
load_config "spark.eventlog.overwrite" ${SPARK_EVENTLOG_OVERWRITE:=false} "spark-defaults.conf" "spark"
load_config "spark.eventlog.buffer.kb" ${SPARK_EVENTLOG_BUFFER_KB:=100k} "spark-defaults.conf" "spark"
load_config "spark.ui.dagGraph.retainedRootRDDs" ${SPARK_UI_DAGGRAPH_RETAINEDROOTRDDS:=NULL} "spark-defaults.conf" "spark"
load_config "spark.ui.enabled" ${SPARK_UI_ENABLED:=true} "spark-defaults.conf" "spark"
load_config "spark.ui.killEnabled" ${SPARK_UI_KILLENABLED:=true} "spark-defaults.conf" "spark"
load_config "spark.ui.liveUpdate.period" ${SPARK_UI_LIVEUPDATE_PERIOD:=NULL} "spark-defaults.conf" "spark"
load_config "spark.ui.liveUpdate.minFlushPeriod" ${SPARK_UI_LIVEUPDATE_MINFLUSHPERIOD:=NULL} "spark-defaults.conf" "spark"
load_config "spark.ui.port" ${SPARK_UI_PORT:=4040} "spark-defaults.conf" "spark"
load_config "spark.ui.retainedJobs" ${SPARK_UI_RETAINEDJOBS:=1000} "spark-defaults.conf" "spark"
load_config "spark.ui.retainedStages" ${SPARK_UI_RETAINEDSTAGES:=1000} "spark-defaults.conf" "spark"
load_config "spark.ui.retainedTasks" ${SPARK_UI_RETAINEDTASKS:=100000} "spark-defaults.conf" "spark"
load_config "spark.ui.reverseProxy" ${SPARK_UI_REVERSEPROXY:=true} "spark-defaults.conf" "spark"
load_config "spark.ui.reverseProxyUrl" ${SPARK_UI_REVERSEPROXYURL:=NULL} "spark-defaults.conf" "spark"
load_config "spark.ui.showConsoleProgress" ${SPARK_UI_SHOWCONSOLEPROGRESS:=true} "spark-defaults.conf" "spark"
load_config "spark.ui.retainedDeadExecutors" ${SPARK_UI_RETAINEDDEADEXECUTORS:=100} "spark-defaults.conf" "spark"
load_config "spark.ui.filters" ${SPARK_UI_FILTERS:=NULL} "spark-defaults.conf" "spark"
load_config "spark.ui.view.acls" ${SPARK_UI_VIEW_ACLS:=NULL} "spark-defaults.conf" "spark"
load_config "spark.ui.view.acls.groups" ${SPARK_UI_VIEW_ACLS_GROUPS:=NULL} "spark-defaults.conf" "spark"
load_config "spark.worker.ui.retainedExecutors" ${SPARK_WORKER_UI_RETAINEDEXECUTORS:=1000} "spark-defaults.conf" "spark"
load_config "spark.worker.ui.retainedDrivers" ${SPARK_WORKER_UI_RETAINEDDRIVERS:=1000} "spark-defaults.conf" "spark"
load_config "spark.sql.ui.retainedExecutions" ${SPARK_SQL_UI_RETAINEDEXECUTIONS:=1000} "spark-defaults.conf" "spark"
load_config "spark.streaming.ui.retainedBatches" ${SPARK_STREAMING_UI_RETAINEDBATCHES:=1000} "spark-defaults.conf" "spark"
load_config "spark.streaming.backpressure.enabled" ${SPARK_STREAMING_BACKPRESSURE_ENABLED:=false} "spark-defaults.conf" "spark"
load_config "spark.streaming.backpressure.initialRate" ${SPARK_STREAMING_BACKPRESSURE_INITIALRATE:=NULL} "spark-defaults.conf" "spark"
load_config "spark.streaming.blockInterval" ${SPARK_STREAMING_BLOCKINTERVAL:=200ms} "spark-defaults.conf" "spark"
load_config "spark.streaming.receiver.maxRate" ${SPARK_STREAMING_RECEIVER_MAXRATE:=NULL} "spark-defaults.conf" "spark"
load_config "spark.streaming.receiver.writeAheadLog.enable" ${SPARK_STREAMING_RECEIVER_WRITEAHEADLOG_ENABLE:=false} "spark-defaults.conf" "spark"
load_config "spark.streaming.receiver.writeAheadLog.closeFileAfterWrite" ${SPARK_STREAMING_RECEIVER_WRITEAHEADLOG_CLOSEFILEAFTERWRITE:=false} "spark-defaults.conf" "spark"
load_config "spark.streaming.unpersist" ${SPARK_STREAMING_UNPERSIST:=true} "spark-defaults.conf" "spark"
load_config "spark.streaming.stopGracefullyOnShutdown" ${SPARK_STREAMING_STOPGRACEFULLYONSHUTDOWN:=false} "spark-defaults.conf" "spark"
load_config "spark.streaming.kafka.maxRatePerPartition" ${SPARK_STREAMING_KAFKA_MAXRATEPERPARTITION:=NULL} "spark-defaults.conf" "spark"
load_config "spark.streaming.kafka.maxRetries" ${SPARK_STREAMING_KAFKA_MAXRETRIES:=1} "spark-defaults.conf" "spark"
load_config "spark.streaming.driver.writeAheadLog.closeFileAfterWrite" ${SPARK_STREAMING_DRIVER_WRITEAHEADLOG_CLOSEFILEAFTERWRITE:=false} "spark-defaults.conf" "spark"
load_config "spark.broadcast.compress" ${SPARK_BROADCAST_COMPRESS:=true} "spark-defaults.conf" "spark"
load_config "spark.broadcast.blockSize" ${SPARK_BROADCAST_BLOCKSIZE:=4m} "spark-defaults.conf" "spark"
load_config "spark.broadcast.checksum" ${SPARK_BROADCAST_CHECKSUM:=NULL} "spark-defaults.conf" "spark"
load_config "spark.checkpoint.compress" ${SPARK_CHECKPOINT_COMPRESS:=NULL} "spark-defaults.conf" "spark"
load_config "spark.io.compression.codec" ${SPARK_IO_COMPRESSION_CODEC:=lz4} "spark-defaults.conf" "spark"
load_config "spark.io.compression.lz4.blockSize" ${SPARK_IO_COMPRESSION_LZ4_BLOCKSIZE:=32k} "spark-defaults.conf" "spark"
load_config "spark.io.compression.snappy.blockSize" ${SPARK_IO_COMPRESSION_SNAPPY_BLOCKSIZE:=32k} "spark-defaults.conf" "spark"
load_config "spark.io.compression.zstd.level" ${SPARK_IO_COMPRESSION_ZSTD_LEVEL:=1} "spark-defaults.conf" "spark"
load_config "spark.io.compression.zstd.bufferSize" ${SPARK_IO_COMPRESSION_ZSTD_BUFFERSIZE:=32k} "spark-defaults.conf" "spark"
load_config "spark.kryo.classesToRegister" ${SPARK_KRYO_CLASSESTOREGISTER:=NULL} "spark-defaults.conf" "spark"
load_config "spark.kryo.referenceTracking" ${SPARK_KRYO_REFERENCETRACKING:=true} "spark-defaults.conf" "spark"
load_config "spark.kryo.registrationRequired" ${SPARK_KRYO_REGISTRATIONREQUIRED:=false} "spark-defaults.conf" "spark"
load_config "spark.kryo.registrator" ${SPARK_KRYO_REGISTRATOR:=NULL} "spark-defaults.conf" "spark"
load_config "spark.kryo.unsafe" ${SPARK_KRYO_UNSAFE:=false} "spark-defaults.conf" "spark"
load_config "spark.kryoserializer.buffer" ${SPARK_KRYOSERIALIZER_BUFFER:=64k} "spark-defaults.conf" "spark"
load_config "spark.kryoserializer.buffer.max" ${SPARK_KRYOSERIALIZER_BUFFER_MAX:=64m} "spark-defaults.conf" "spark"
load_config "spark.rdd.compress" ${SPARK_RDD_COMPRESS:=false} "spark-defaults.conf" "spark"
load_config "spark.serializer" ${SPARK_SERIALIZER:=org.apache.spark.serializer.JavaSerializer} "spark-defaults.conf" "spark"
load_config "spark.serializer.objectStreamReset" ${SPARK_SERIALIZER_OBJECTSTREAMRESET:=100} "spark-defaults.conf" "spark"
load_config "spark.memory.fraction" ${SPARK_MEMORY_FRACTION:=0.6} "spark-defaults.conf" "spark"
load_config "spark.memory.storageFraction" ${SPARK_MEMORY_STORAGEFRACTION:=0.5} "spark-defaults.conf" "spark"
load_config "spark.memory.offHeap.enabled" ${SPARK_MEMORY_OFFHEAP_ENABLED:=false} "spark-defaults.conf" "spark"
load_config "spark.memory.offHeap.size" ${SPARK_MEMORY_OFFHEAP_SIZE:=0} "spark-defaults.conf" "spark"
load_config "spark.memory.useLegacyMode" ${SPARK_MEMORY_USELEGACYMODE:=false} "spark-defaults.conf" "spark"
load_config "spark.storage.memoryFraction" ${SPARK_STORAGE_MEMORYFRACTION:=0.2} "spark-defaults.conf" "spark"
load_config "spark.storage.unrollFraction" ${SPARK_STORAGE_UNROLLFRACTION:=0.6} "spark-defaults.conf" "spark"
load_config "spark.storage.replication.proactive" ${SPARK_STORAGE_REPLICATION_PROACTIVE:=false} "spark-defaults.conf" "spark"
load_config "spark.storage.memoryMapThreshold" ${SPARK_STORAGE_MEMORYMAPTHRESHOLD:=2m} "spark-defaults.conf" "spark"
load_config "spark.cleaner.periodicGC.interval" ${SPARK_CLEANER_PERIODICGC_INTERVAL:=30min} "spark-defaults.conf" "spark"
load_config "spark.cleaner.referenceTracking" ${SPARK_CLEANER_REFERENCETRACKING:=true} "spark-defaults.conf" "spark"
load_config "spark.cleaner.referenceTracking.blocking" ${SPARK_CLEANER_REFERENCETRACKING_BLOCKING:=true} "spark-defaults.conf" "spark"
load_config "spark.cleaner.referenceTracking.blocking.shuffle" ${SPARK_CLEANER_REFERENCETRACKING_BLOCKING_SHUFFLE:=false} "spark-defaults.conf" "spark"
load_config "spark.cleaner.referenceTracking.cleanCheckpoints" ${SPARK_CLEANER_REFERENCETRACKING_CLEANCHECKPOINTS:=false} "spark-defaults.conf" "spark"
load_config "spark.hadoop.cloneConf" ${SPARK_HADOOP_CLONECONF:=false} "spark-defaults.conf" "spark"
load_config "spark.hadoop.validateOutputSpecs" ${SPARK_HADOOP_VALIDATEOUTPUTSPECS:=true} "spark-defaults.conf" "spark"
load_config "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version" ${SPARK_HADOOP_MAPREDUCE_FILEOUTPUTCOMMITTER_ALGORITHM_VERSION:=1} "spark-defaults.conf" "spark"
load_config "spark.rpc.message.maxSize" ${SPARK_RPC_MESSAGE_MAXSIZE:=128} "spark-defaults.conf" "spark"
load_config "spark.rpc.io.backLog" ${SPARK_RPC_IO_BACKLOG:=NULL} "spark-defaults.conf" "spark"
load_config "spark.rpc.numRetries" ${SPARK_RPC_NUMRETRIES:=3} "spark-defaults.conf" "spark"
load_config "spark.rpc.retry.wait" ${SPARK_RPC_RETRY_WAIT:=3s} "spark-defaults.conf" "spark"
load_config "spark.rpc.askTimeout" ${SPARK_RPC_ASKTIMEOUT:=120s} "spark-defaults.conf" "spark"
load_config "spark.rpc.lookupTimeout" ${SPARK_RPC_LOOKUPTIMEOUT:=120s} "spark-defaults.conf" "spark"
load_config "spark.blockManager.port" ${SPARK_BLOCKMANAGER_PORT:=NULL} "spark-defaults.conf" "spark"
load_config "spark.port.maxRetries" ${SPARK_PORT_MAXRETRIES:=16} "spark-defaults.conf" "spark"
load_config "spark.cores.max" ${SPARK_CORES_MAX:=NULL} "spark-defaults.conf" "spark"
load_config "spark.locality.wait" ${SPARK_LOCALITY_WAIT:=3s} "spark-defaults.conf" "spark"
load_config "spark.locality.wait.node" ${SPARK_LOCALITY_WAIT_NODE:=NULL} "spark-defaults.conf" "spark"
load_config "spark.locality.wait.process" ${SPARK_LOCALITY_WAIT_PROCESS:=NULL} "spark-defaults.conf" "spark"
load_config "spark.locality.wait.rack" ${SPARK_LOCALITY_WAIT_RACK:=NULL} "spark-defaults.conf" "spark"
load_config "spark.scheduler.maxRegisteredResourcesWaitingTime" ${SPARK_SCHEDULER_MAXREGISTEREDRESOURCESWAITINGTIME:=30s} "spark-defaults.conf" "spark"
load_config "spark.scheduler.minRegisteredResourcesRation" ${SPARK_SCHEDULER_MINREGISTEREDRESOURCESRATION:=0.0} "spark-defaults.conf" "spark"
load_config "spark.scheduler.mode" ${SPARK_SCHEDULER_MODE:=FIFO} "spark-defaults.conf" "spark"
load_config "spark.scheduler.revive.interval" ${SPARK_SCHEDULER_REVIVE_INTERVAL:=1s} "spark-defaults.conf" "spark"
load_config "spark.scheduler.listenerbus.eventqueue.capacity" ${SPARK_SCHEDULER_LISTENERBUS_EVENTQUEUE_CAPACITY:=10000} "spark-defaults.conf" "spark"
load_config "spark.scheduler.blacklist.unschedulableTaskSetTimeout" ${SPARK_SCHEDULER_BLACKLIST_UNSCHEDULABLETASKSETTIMEOUT:=NULL} "spark-defaults.conf" "spark"
load_config "spark.blacklist.enabled" ${SPARK_BLACKLIST_ENABLED:=false} "spark-defaults.conf" "spark"
load_config "spark.blacklist.timeout" ${SPARK_BLACKLIST_TIMEOUT:=1h} "spark-defaults.conf" "spark"
load_config "spark.blacklist.task.maxTaskAttemptsPerExecutor" ${SPARK_BLACKLIST_TASK_MAXTASKATTEMPTSPEREXECUTOR:=1} "spark-defaults.conf" "spark"
load_config "spark.blacklist.task.maxTaskAttemptsPerNode" ${SPARK_BLACKLIST_TASK_MAXTASKATTEMPTSPERNODE:=2} "spark-defaults.conf" "spark"
load_config "spark.blacklist.stage.maxFailedTaskPerExecutor" ${SPARK_BLACKLIST_STAGE_MAXFAILEDTASKPEREXECUTOR:=2} "spark-defaults.conf" "spark"
load_config "spark.blacklist.stage.maxFailedExecutorsPerNode" ${SPARK_BLACKLIST_STAGE_MAXFAILEDEXECUTORSPERNODE:=2} "spark-defaults.conf" "spark"
load_config "spark.blacklist.application.maxFailedTasksPerExecutor" ${SPARK_BLACKLIST_APPLICATION_MAXFAILEDTASKSPEREXECUTOR:=2} "spark-defaults.conf" "spark"
load_config "spark.blacklist.application.maxFailedExecutorsPerNode" ${SPARK_BLACKLIST_APPLICATION_MAXFAILEDEXECUTORSPERNODE:=2} "spark-defaults.conf" "spark"
load_config "spark.blacklist.application.fetchFailure.enabled" ${SPARK_BLACKLIST_APPLICATION_FETCHFAILURE_ENABLED:=false} "spark-defaults.conf" "spark"
load_config "spark.blacklist.killBlacklistedExecutors" ${SPARK_BLACKLIST_KILLBLACKLISTEDEXECUTORS:=false} "spark-defaults.conf" "spark"
load_config "spark.speculation" ${SPARK_SPECULATION:=false} "spark-defaults.conf" "spark"
load_config "spark.speculation.interval" ${SPARK_SPECULATION_INTERVAL:=100ms} "spark-defaults.conf" "spark"
load_config "spark.speculation.multiplier" ${SPARK_SPECULATION_MULTIPLIER:=1.5} "spark-defaults.conf" "spark"
load_config "spark.speculation.quantile" ${SPARK_SPECULATION_QUANTILE:=0.75} "spark-defaults.conf" "spark"
load_config "spark.task.cpus" ${SPARK_TASK_CPUS:=1} "spark-defaults.conf" "spark"
load_config "spark.task.maxFailures" ${SPARK_TASK_MAXFAILURES:=4} "spark-defaults.conf" "spark"
load_config "spark.task.reaper.enabled" ${SPARK_TASK_REAPER_ENABLED:=false} "spark-defaults.conf" "spark"
load_config "spark.task.reaper.pollingInterval" ${SPARK_TASK_REAPER_POLLINGINTERVAL:=10s} "spark-defaults.conf" "spark"
load_config "spark.task.reaper.threadDump" ${SPARK_TASK_REAPER_THREADDUMP:=true} "spark-defaults.conf" "spark"
load_config "spark.task.reaper.killTimeout" ${SPARK_TASK_REAPER_KILLTIMEOUT:=-1} "spark-defaults.conf" "spark"
load_config "spark.stage.maxConsecutiveAttempts" ${SPARK_STAGE_MAXCONSECUTIVEATTEMPTS:=4} "spark-defaults.conf" "spark"
load_config "spark.dynamicAllocation.enabled" ${SPARK_DYNAMICALLOCATION_ENABLED:=false} "spark-defaults.conf" "spark"
load_config "spark.dynamicAllocation.executorIdleTimeout" ${SPARK_DYNAMICALLOCATION_EXECUTORIDLETIMEOUT:=60s} "spark-defaults.conf" "spark"
load_config "spark.dynamicAllocation.initialExecutors" ${SPARK_DYNAMICALLOCATION_INITIALEXECUTORS:=NULL} "spark-defaults.conf" "spark"
load_config "spark.dynamicAllocation.cachedExecutorIdleTimeout" ${SPARK_DYNAMICALLOCATION_CACHEDEXECUTORIDLETIMEOUT:=infinity} "spark-defaults.conf" "spark"
load_config "spark.dynamicAllocation.maxExecutors" ${SPARK_DYNAMICALLOCATION_MAXEXECUTORS:=infinity} "spark-defaults.conf" "spark"
load_config "spark.dynamicAllocation.minExecutors" ${SPARK_DYNAMICALLOCATION_MINEXECUTORS:=0} "spark-defaults.conf" "spark"
load_config "spark.dynamicAllocation.executorAllocationRatio" ${SPARK_DYNAMICALLOCATION_EXECUTORALLOCATIONRATIO:=NULL} "spark-defaults.conf" "spark"
load_config "spark.dynamicAllocation.schedulerBacklogTimeout" ${SPARK_DYNAMICALLOCATION_SCHEDULERBACKLOGTIMEOUT:=1s} "spark-defaults.conf" "spark"
load_config "spark.acls.enabled" ${SPARK_ACLS_ENABLED:=false} "spark-defaults.conf" "spark"
load_config "spark.admin.acls" ${SPARK_ADMIN_ACLS:=NULL} "spark-defaults.conf" "spark"
load_config "spark.admin.acls.groups" ${SPARK_ADMIN_ACLS_GROUPS:=NULL} "spark-defaults.conf" "spark"
load_config "spark.user.groups.mapping" ${SPARK_USER_GROUPS_MAPPING:=org.apache.spark.security.ShellBasedGroupsMappingProvider} "spark-defaults.conf" "spark"
load_config "spark.authenticate" ${SPARK_AUTHENTICATE:=false} "spark-defaults.conf" "spark"
load_config "spark.authenticate.secret" ${SPARK_AUTHENTICATE_SECRET:=NULL} "spark-defaults.conf" "spark"
load_config "spark.authenticate.enableSaslEncrpytion" ${SPARK_AUTHENTICATE_ENABLESASLENCRPYTION:=false} "spark-defaults.conf" "spark"
load_config "spark.network.crypto.enabled" ${SPARK_NETWORK_CRYPTO_ENABLED:=false} "spark-defaults.conf" "spark"
load_config "spark.network.crypto.keyLength" ${SPARK_NETWORK_CRYPTO_KEYLENGTH:=128} "spark-defaults.conf" "spark"
load_config "spark.network.crypto.keyFactoryAlgorithm" ${SPARK_NETWORK_CRYPTO_KEYFACTORYALGORITHM:=PBKDF2WithHmacSHA1} "spark-defaults.conf" "spark"
load_config "spark.network.crypto.saslFallback" ${SPARK_NETWORK_CRYPTO_SASLFALLBACK:=true} "spark-defaults.conf" "spark"
load_config "spark.network.sasl.serverAlwaysEncrypt" ${SPARK_NETWORK_SASL_SERVERALWAYSENCRYPT:=false} "spark-defaults.conf" "spark"
load_config "spark.core.connection.ack.wait.timeout" ${SPARK_CORE_CONNECTION_ACK_WAIT_TIMEOUT:=NULL} "spark-defaults.conf" "spark"
load_config "spark.modify.acls" ${SPARK_MODIFY_ACLS:=NULL} "spark-defaults.conf" "spark"
load_config "spark.modify.acls.groups" ${SPARK_MODIFY_ACLS_GROUPS:=NULL} "spark-defaults.conf" "spark"
load_config "spark.ssl.enabled" ${SPARK_SSL_ENABLED:=false} "spark-defaults.conf" "spark"
load_config "spark.ssl.enabledAlgorithms" ${SPARK_SSL_ENABLEDALGORITHMS:=NULL} "spark-defaults.conf" "spark"
load_config "spark.ssl.keyPassword" ${SPARK_SSL_KEYPASSWORD:=NULL} "spark-defaults.conf" "spark"
load_config "spark.ssl.keyStore" ${SPARK_SSL_KEYSTORE:=NULL} "spark-defaults.conf" "spark"
load_config "spark.ssl.keyStorePassword" ${SPARK_SSL_KEYSTOREPASSWORD:=NULL} "spark-defaults.conf" "spark"
load_config "spark.ssl.keyStoreType" ${SPARK_SSL_KEYSTORETYPE:=JKS} "spark-defaults.conf" "spark"
load_config "spark.ssl.protocol" ${SPARK_SSL_PROTOCOL:=NULL} "spark-defaults.conf" "spark"
load_config "spark.ssl.needClientAuth" ${SPARK_SSL_NEEDCLIENTAUTH:=false} "spark-defaults.conf" "spark"
load_config "spark.ssl.trustStore" ${SPARK_SSL_TRUSTSTORE:=NULL} "spark-defaults.conf" "spark"
load_config "spark.ssl.trustStorePassword" ${SPARK_SSL_TRUSTSTOREPASSWORD:=NULL} "spark-defaults.conf" "spark"
load_config "spark.ssl.trustStoreType" ${SPARK_SSL_TRUSTSTORETYPE:=JKS} "spark-defaults.conf" "spark"
load_config "spark.graphx.pregel.checkpointInterval" ${SPARK_GRAPHX_PREGEL_CHECKPOINTINTERVAL:=-1} "spark-defaults.conf" "spark"
load_config "spark.deploy.recoveryMode" ${SPARK_DEPLOY_RECOVERYMODE:=NULL} "spark-defaults.conf" "spark"
load_config "spark.deploy.zookeeper.url" ${SPARK_DEPLOY_ZOOKEEPER_URL:=NULL} "spark-defaults.conf" "spark"
load_config "spark.deploy.zookeeper.dir" ${SPARK_DEPLOY_ZOOKEEPER_DIR:=NULL} "spark-defaults.conf" "spark"
load_config "spark.yarn.am.memory" ${SPARK_YARN_AM_MEMORY:=NULL} "spark-defaults.conf" "spark"
load_config "spark.yarn.am.cores" ${SPARK_YARN_AM_CORES:=NULL} "spark-defaults.conf" "spark"
load_config "spark.yarn.am.waitTime" ${SPARK_YARN_AM_WAITTIME:=NULL} "spark-defaults.conf" "spark"
load_config "spark.yarn.am.memoryOverhead" ${SPARK_YARN_AM_MEMORYOVERHEAD:=NULL} "spark-defaults.conf" "spark"
load_config "spark.yarn.am.extraJavaOptions" ${SPARK_YARN_AM_EXTRAJAVAOPTIONS:=NULL} "spark-defaults.conf" "spark"
load_config "spark.yarn.am.extraLibraryPath" ${SPARK_YARN_AM_EXTRALIBRARYPATH:=NULL} "spark-defaults.conf" "spark"
load_config "spark.yarn.am.attemptFailuresValidityInterval" ${SPARK_YARN_AM_ATTEMPTFAILURESVALIDITYINTERVAL:=NULL} "spark-defaults.conf" "spark"
load_config "spark.yarn.am.nodeLabelExpression" ${SPARK_YARN_AM_NODELABELEXPRESSION:=NULL} "spark-defaults.conf" "spark"
load_config "spark.yarn.submit.file.replication" ${SPARK_YARN_SUBMIT_FILE_REPLICATION:=NULL} "spark-defaults.conf" "spark"
load_config "spark.yarn.submit.waitAppCompletion" ${SPARK_YARN_SUBMIT_WAITAPPCOMPLETION:=NULL} "spark-defaults.conf" "spark"
load_config "spark.yarn.stagingDir" ${SPARK_YARN_STAGINGDIR:=NULL} "spark-defaults.conf" "spark"
load_config "spark.yarn.preserve.staging.files" ${SPARK_YARN_PRESERVE_STAGING_FILES:=NULL} "spark-defaults.conf" "spark"
load_config "spark.yarn.scheduler.heartbeat.interval-ms" ${SPARK_YARN_SCHEDULER_HEARTBEAT_INTERVAL_MS:=NULL} "spark-defaults.conf" "spark"
load_config "spark.yarn.scheduler.initial-allocation.interval" ${SPARK_YARN_SCHEDULER_INITIAL_ALLOCATION_INTERVAL:=NULL} "spark-defaults.conf" "spark"
load_config "spark.yarn.max.executor.failures" ${SPARK_YARN_MAX_EXECUTOR_FAILURES:=NULL} "spark-defaults.conf" "spark"
load_config "spark.yarn.historyServer.address" ${SPARK_YARN_HISTORYSERVER_ADDRESS:=NULL} "spark-defaults.conf" "spark"
load_config "spark.yarn.dist.files" ${SPARK_YARN_DIST_FILES:=NULL} "spark-defaults.conf" "spark"
load_config "spark.yarn.dist.jars" ${SPARK_YARN_DIST_JARS:=NULL} "spark-defaults.conf" "spark"
load_config "spark.yarn.dist.forceDownloadSchemes" ${SPARK_YARN_DIST_FORCEDOWNLOADSCHEMES:=NULL} "spark-defaults.conf" "spark"
load_config "spark.yarn.queue" ${SPARK_YARN_QUEUE:=NULL} "spark-defaults.conf" "spark"
load_config "spark.yarn.jars" ${SPARK_YARN_JARS:=NULL} "spark-defaults.conf" "spark"
load_config "spark.yarn.archive" ${SPARK_YARN_ARCHIVE:=NULL} "spark-defaults.conf" "spark"
load_config "spark.yarn.containerLauncherMaxThreads" ${SPARK_YARN_CONTAINERLAUNCHERMAXTHREADS:=NULL} "spark-defaults.conf" "spark"
load_config "spark.yarn.maxAppAttempts" ${SPARK_YARN_MAXAPPATTEMPTS:=NULL} "spark-defaults.conf" "spark"
load_config "spark.yarn.executor.failuresValidityInterval" ${SPARK_YARN_EXECUTOR_FAILURESVALIDITYINTERVAL:=NULL} "spark-defaults.conf" "spark"
load_config "spark.yarn.executor.nodeLabelExpression" ${SPARK_YARN_EXECUTOR_NODELABELEXPRESSION:=NULL} "spark-defaults.conf" "spark"
load_config "spark.yarn.tags" ${SPARK_YARN_TAGS:=NULL} "spark-defaults.conf" "spark"
load_config "spark.yarn.config.gatewayPath" ${SPARK_YARN_CONFIG_GATEWAYPATH:=NULL} "spark-defaults.conf" "spark"
load_config "spark.yarn.config.replacementPath" ${SPARK_YARN_CONFIG_REPLACEMENTPATH:=NULL} "spark-defaults.conf" "spark"
load_config "spark.yarn.rolledLog.includePattern" ${SPARK_YARN_ROLLEDLOG_INCLUDEPATTERN:=NULL} "spark-defaults.conf" "spark"
load_config "spark.yarn.rolledLog.excludePattern" ${SPARK_YARN_ROLLEDLOG_EXCLUDEPATTERN:=NULL} "spark-defaults.conf" "spark"
load_config "spark.yarn.blacklist.executor.launch.blacklisting.enabled" ${SPARK_YARN_BLACKLIST_EXECUTOR_LAUNCH_BLACKLISTING_ENABLED:=NULL} "spark-defaults.conf" "spark"
load_config "spark.yarn.metrics.namespace" ${SPARK_YARN_METRICS_NAMESPACE:=NULL} "spark-defaults.conf" "spark"
load_config "livy.keystore" ${LIVY_KEYSTORE:=NULL} "livy.conf" "livy"
load_config "livy.keystore.password" ${LIVY_KEYSTORE_PASSWORD:=NULL} "livy.conf" "livy"
load_config "livy.key-password" ${LIVY_KEY_PASSWORD:=NULL} "livy.conf" "livy"
load_config "livy.hadoop.security.credential.provider.path" ${LIVY_HADOOP_SECURITY_CREDENTIAL_PROVIDER_PATH:=NULL} "livy.conf" "livy"
load_config "livy.server.host" ${LIVY_SERVER_HOST:=0.0.0.0} "livy.conf" "livy"
load_config "livy.server.port" ${LIVY_SERVER_PORT:=8998} "livy.conf" "livy"
load_config "livy.server.request-header.size" ${LIVY_SERVER_REQUEST_HEADER_SIZE:=131072} "livy.conf" "livy"
load_config "livy.server.response-header.size" ${LIVY_SERVER_RESPONSE_HEADER_SIZE:=131072} "livy.conf" "livy"
load_config "livy.server.session.timeout-check" ${LIVY_SERVER_SESSION_TIMEOUT_CHECK:=true} "livy.conf" "livy"
load_config "livy.server.session.timeout" ${LIVY_SERVER_SESSION_TIMEOUT:=1h} "livy.conf" "livy"
load_config "livy.server.session.state-retain.sec" ${LIVY_SERVER_SESSION_STATE_RETAIN_SEC:=600s} "livy.conf" "livy"
load_config "livy.server.csrf-protection.enabled" ${LIVY_SERVER_CSRF_PROTECTION_ENABLED:=NULL} "livy.conf" "livy"
load_config "livy.server.recovery.mode" ${LIVY_SERVER_RECOVERY_MODE:=off} "livy.conf" "livy"
load_config "livy.server.recovery.state-store" ${LIVY_SERVER_RECOVERY_STATE_STORE:=NULL} "livy.conf" "livy"
load_config "livy.server.recovery.state-store.url" ${LIVY_SERVER_RECOVERY_STATE_STORE_URL:=NULL} "livy.conf" "livy"
load_config "livy.server.yarn.app-lookup-timeout" ${LIVY_SERVER_YARN_APP_LOOKUP_TIMEOUT:=120s} "livy.conf" "livy"
load_config "livy.server.yarn.app-leakage.check-timeout" ${LIVY_SERVER_YARN_APP_LEAKAGE_CHECK_TIMEOUT:=600s} "livy.conf" "livy"
load_config "livy.server.yarn.app-leakage.check-interval" ${LIVY_SERVER_YARN_APP_LEAKAGE_CHECK_INTERVAL:=60s} "livy.conf" "livy"
load_config "livy.server.yarn.poll-interval" ${LIVY_SERVER_YARN_POLL_INTERVAL:=5s} "livy.conf" "livy"
load_config "livy.server.request-log-retain.days" ${LIVY_SERVER_REQUEST_LOG_RETAIN_DAYS:=5} "livy.conf" "livy"
load_config "livy.server.access-control.enabled" ${LIVY_SERVER_ACCESS_CONTROL_ENABLED:=false} "livy.conf" "livy"
load_config "livy.server.access-control.allowed-users" ${LIVY_SERVER_ACCESS_CONTROL_ALLOWED_USERS:=*} "livy.conf" "livy"
load_config "livy.server.access-control.modify-users" ${LIVY_SERVER_ACCESS_CONTROL_MODIFY_USERS:=NULL} "livy.conf" "livy"
load_config "livy.server.access-control.view-users" ${LIVY_SERVER_ACCESS_CONTROL_VIEW_USERS:=NULL} "livy.conf" "livy"
load_config "livy.server.auth.type" ${LIVY_SERVER_AUTH_TYPE:=NULL} "livy.conf" "livy"
load_config "livy.server.auth.kerberos.principal" ${LIVY_SERVER_AUTH_KERBEROS_PRINCIPAL:=NULL} "livy.conf" "livy"
load_config "livy.server.auth.kerberos.keytab" ${LIVY_SERVER_AUTH_KERBEROS_KEYTAB:=NULL} "livy.conf" "livy"
load_config "livy.server.auth.kerberos.name-rules" ${LIVY_SERVER_AUTH_KERBEROS_NAME_RULES:=NULL} "livy.conf" "livy"
load_config "livy.ui.basePath" ${LIVY_UI_BASEPATH:=NULL} "livy.conf" "livy"
load_config "livy.ui.enabled" ${LIVY_UI_ENABLED:=true} "livy.conf" "livy"
load_config "livy.spark.master" ${LIVY_SPARK_MASTER:=yarn} "livy.conf" "livy"
load_config "livy.spark.deployMode" ${LIVY_SPARK_DEPLOYMODE:=client} "livy.conf" "livy"
load_config "livy.impersonation.enabled" ${LIVY_IMPERSONATION_ENABLED:=true} "livy.conf" "livy"
load_config "livy.cache-log.size" ${LIVY_CACHE_LOG_SIZE:=200} "livy.conf" "livy"
load_config "livy.rsc.jars" ${LIVY_RSC_JARS:=NULL} "livy.conf" "livy"
load_config "livy.repl.jars" ${LIVY_REPL_JARS:=NULL} "livy.conf" "livy"
load_config "livy.repl.enable-hive-context" ${LIVY_REPL_ENABLE_HIVE_CONTEXT:=NULL} "livy.conf" "livy"
load_config "livy.pyspark.archives" ${LIVY_PYSPARK_ARCHIVES:=NULL} "livy.conf" "livy"
load_config "livy.sparkr.package" ${LIVY_SPARKR_PACKAGE:=NULL} "livy.conf" "livy"
load_config "livy.file.local-dir-whitelist" ${LIVY_FILE_LOCAL_DIR_WHITELIST:=NULL} "livy.conf" "livy"

# Add Hadoop JARs to Spark classpath
cp "${SPARK_HOME}/conf/spark-env.sh.template" "${SPARK_HOME}/conf/spark-env.sh"
echo "SPARK_DIST_CLASSPATH=\$(hadoop classpath)" >> "${SPARK_HOME}/conf/spark-env.sh"
